

# Local/Offline Considerations




# Tools


## Anything LLM
https://github.com/Mintplex-Labs/anything-llm



## Ollama

ollama.com

https://github.com/ollama/ollama

Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models. 


## GPT4All

nomic.ai/gpt4all

https://github.com/nomic-ai/gpt4all

 GPT4All runs large language models (LLMs) privately on everyday desktops & laptops.

No API calls or GPUs required - you can just download the application and get started. 



## Llama.cpp

https://github.com/ggerganov/llama.cpp

Inference of Meta's LLaMA model (and others) in pure C/C++

The main goal of llama.cpp is to enable LLM inference with minimal setup and state-of-the-art performance on a wide variety of hardware - locally and in the cloud.

    Plain C/C++ implementation without any dependencies
    Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks
    AVX, AVX2, AVX512 and AMX support for x86 architectures
    1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use
    Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads MTT GPUs via MUSA)
    Vulkan and SYCL backend support
    CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity

Since its inception, the project has improved significantly thanks to many contributions. It is the main playground for developing new features for the ggml library.


## gpt4free

The official gpt4free repository | various collection of powerful language models 

g4f.ai

https://github.com/xtekky/gpt4free



## private-gpt

PrivateGPT is a production-ready AI project that allows you to ask questions about your documents using the power of Large Language Models (LLMs), even in scenarios without an Internet connection. 100% private, no data leaves your execution environment at any point.

https://github.com/zylon-ai/private-gpt

 privategpt.dev 

 ## Open WebUI

 Open WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs. For more information, be sure to check out our Open WebUI Documentation.

 https://github.com/open-webui/open-webui

  openwebui.com 


## Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.
Supports speech-synthesis, multi-modal, and extensible (function call) plugin system.

https://github.com/lobehub/lobe-chat

 chat-preview.lobehub.com 

 ## Text generation web UI

A Gradio web UI for Large Language Models.

Its goal is to become the AUTOMATIC1111/stable-diffusion-webui of text generation.

https://github.com/oobabooga/text-generation-webui


## vllm

vLLM is a fast and easy-to-use library for LLM inference and serving.

vLLM is fast with:

    State-of-the-art serving throughput
    Efficient management of attention key and value memory with PagedAttention
    Continuous batching of incoming requests
    Fast model execution with CUDA/HIP graph
    Quantizations: GPTQ, AWQ, INT4, INT8, and FP8.
    Optimized CUDA kernels, including integration with FlashAttention and FlashInfer.
    Speculative decoding
    Chunked prefill

https://github.com/vllm-project/vllm


## AnythingLLM

AnythingLLM: The all-in-one AI app you were looking for.
Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required. 

https://github.com/Mintplex-Labs/anything-llm

anythingllm.com


## jan

Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM) 

https://github.com/janhq/jan

jan.ai/

## localGPT

LocalGPT is an open-source initiative that allows you to converse with your documents without compromising your privacy. With everything running locally, you can be assured that no data ever leaves your computer. Dive into the world of secure, local document interactions with LocalGPT.

https://github.com/PromtEngineer/localGPT


