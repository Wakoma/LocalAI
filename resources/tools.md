# Table of Contents

- [Table of Contents](#table-of-contents)
- [General Resources](#general-resources)
  - [Leaderboards](#leaderboards)
    - [Livebench](#livebench)
  - [Models](#models)
  - [Wiki Articles](#wiki-articles)
  - [Reddit Groups and Discussions](#reddit-groups-and-discussions)
  - [Awesome Lists](#awesome-lists)
  - [Prompt Engineering](#prompt-engineering)
  - [AI research](#ai-research)
- [Running LLM on Android](#running-llm-on-android)
  - [Maid - Mobile Artificial Intelligence Distribution](#maid---mobile-artificial-intelligence-distribution)
  - [MLC LLM](#mlc-llm)
  - [ChatterUI](#chatterui)
  - [smolchat Android](#smolchat-android)
- [Running LLM on Docker](#running-llm-on-docker)
  - [Open WebUI](#open-webui)
  - [Ollama](#ollama)
  - [OpenVINO](#openvino)
  - [PrivateGPT](#privategpt)
- [Text Generation](#text-generation)
  - [llamafile](#llamafile)
  - [smol-tools](#smol-tools)
  - [SmolLM2](#smollm2)
  - [smol-course](#smol-course)
  - [Anything LLM](#anything-llm)
  - [Ollama](#ollama-1)
  - [GPT4All](#gpt4all)
  - [Llama.cpp](#llamacpp)
  - [gpt4free](#gpt4free)
  - [private-gpt](#private-gpt)
  - [Open WebUI](#open-webui-1)
  - [Lobe Chat](#lobe-chat)
  - [Text generation web UI](#text-generation-web-ui)
  - [vllm](#vllm)
  - [AnythingLLM](#anythingllm)
  - [jan](#jan)
  - [localGPT](#localgpt)
  - [koboldcpp](#koboldcpp)
- [Text - Translation](#text---translation)
- [Text - RAG](#text---rag)
  - [Sort](#sort)
  - [Datasets](#datasets)
  - [WikiChat](#wikichat)
  - [Android-Document-QA](#android-document-qa)
- [Code](#code)
  - [Why might this be useful for community networking and/or capacity building?](#why-might-this-be-useful-for-community-networking-andor-capacity-building)
  - [Qwen2.5](#qwen25)
  - [Claude 3.5 Sonnet](#claude-35-sonnet)
- [Image Generation](#image-generation)
  - [Fooocus](#fooocus)
  - [Generative AI for Krita](#generative-ai-for-krita)
  - [SD.Next](#sdnext)
  - [Stable Diffusion web UI](#stable-diffusion-web-ui)
  - [ComfyUI](#comfyui)
- [Audio](#audio)
  - [Whisper](#whisper)
      - [How to install and use Whisper offline (no internet required)](#how-to-install-and-use-whisper-offline-no-internet-required)
  - [local-talking-llm](#local-talking-llm)
  - [Music](#music)
    - [FluxMusic](#fluxmusic)
    - [OpenMusic](#openmusic)
- [Video Generation](#video-generation)
  - [Awesome Video Diffusion](#awesome-video-diffusion)
  - [CogVideo](#cogvideo)
  - [LTX-Video](#ltx-video)
- [CAD Generation](#cad-generation)
  - [Why might this be useful for community networking and/or capacity building?](#why-might-this-be-useful-for-community-networking-andor-capacity-building-1)
  - [Trellis](#trellis)
  - [Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts](#text2cad-generating-sequential-cad-designs-from-beginner-to-expert-level-text-prompts)



# General Resources

LocalML Zotero Library: https://www.zotero.org/groups/5718368/localml/library

https://huggingface.co/docs

https://github.com/huggingface

https://github.com/huggingface/transformers

## Leaderboards

### Livebench
https://livebench.ai/#/



## Models


https://huggingface.co/models

https://github.com/Troyanovsky/Local-LLM-Comparison-Colab-UI

https://www.openml.org/


## Wiki Articles
https://en.wikipedia.org/wiki/Generative_artificial_intelligence

## Reddit Groups and Discussions
https://www.reddit.com/r/LocalLLaMA/

https://www.reddit.com/r/MachineLearning/

https://www.reddit.com/r/MLQuestions/


Can a 3b model with sufficiently high quality training data outperform a 70b models at specialized tasks?  https://www.reddit.com/r/LocalLLaMA/comments/1h9c6cu/can_a_3b_model_with_sufficiently_high_quality/

## Awesome Lists

https://github.com/janhq/awesome-local-ai

https://github.com/vince-lam/awesome-local-llms

https://github.com/mahseema/awesome-ai-tools

https://github.com/steven2358/awesome-generative-ai

## Prompt Engineering


https://www.promptingguide.ai/

https://github.com/dair-ai/Prompt-Engineering-Guide

https://github.com/f/awesome-chatgpt-prompts


 ## AI research 

https://github.com/youssefHosni/Awesome-AI-Data-GitHub-Repos

 https://github.com/aimerou/awesome-ai-papers

 https://github.com/DefTruth/Awesome-LLM-Inference



# Running LLM on Android


## Maid - Mobile Artificial Intelligence Distribution

Maid is a cross-platform free and an open-source application for interfacing with llama.cpp models locally, and remotely with Ollama, Mistral, Google Gemini and OpenAI models remotely. Maid supports sillytavern character cards to allow you to interact with all your favorite characters. Maid supports downloading a curated list of Models in-app directly from huggingface.

https://github.com/Mobile-Artificial-Intelligence/maid

## MLC LLM

MLC LLM is a machine learning compiler and high-performance deployment engine for large language models. The mission of this project is to enable everyone to develop, optimize, and deploy AI models natively on everyone's platforms. 

https://github.com/mlc-ai/mlc-llm

## ChatterUI
ChatterUI is a native mobile frontend for LLMs.

Run LLMs on device or connect to various commercial or open source APIs. ChatterUI aims to provide a mobile-friendly interface with fine-grained control over chat structuring.

https://github.com/Vali-98/ChatterUI


## smolchat Android

Project Goals

    Provide a usable user interface to interact with local SLMs (small language models) locally, on-device
    Allow users to add/remove SLMs (GGUF models) and modify their system prompts or inference parameters (temperature, min-p)
    Allow users to create specific-downstream tasks quickly and use SLMs to generate responses
    Simple, easy to understand, extensible codebase


https://github.com/shubham0204/SmolChat-Android


# Running LLM on Docker

Discussion: https://www.reddit.com/r/LocalLLaMA/comments/17v5r0p/a_fun_day_evaluating_llm_chat_guisservers_in/

## Open WebUI
https://github.com/open-webui/open-webui

https://docs.openwebui.com/

## Ollama
https://hub.docker.com/r/ollama/ollama

## OpenVINO
https://docs.openvino.ai/2024/index.html

## PrivateGPT
https://github.com/zylon-ai/private-gpt



# Text Generation



## llamafile

llamafile lets you distribute and run LLMs with a single file. 

https://github.com/Mozilla-Ocho/llamafile






## smol-tools

A collection of lightweight AI-powered tools built with LLaMA.cpp and small language models. These tools are designed to run locally on your machine without requiring expensive GPU resources. They can also run offline, without any internet connection.

https://github.com/huggingface/smollm/blob/main/smol_tools/README.md


## SmolLM2


SmolLM2 is a family of compact language models available in three size: 135M, 360M, and 1.7B parameters. They are capable of solving a wide range of tasks while being lightweight enough to run on-device.

https://github.com/huggingface/smollm/tree/main


## smol-course

This is a practical course on aligning language models for your specific use case. It's a handy way to get started with aligning language models, because everything runs on most local machines. There are minimal GPU requirements and no paid services. The course is based on the SmolLM2 series of models, but you can transfer the skills you learn here to larger models or other small language models.

https://github.com/huggingface/smol-course

Why Small Language Models?

While large language models have shown impressive capabilities, they often require significant computational resources and can be overkill for focused applications. Small language models offer several advantages for domain-specific applications:

    Efficiency: Require significantly less computational resources to train and deploy
    Customization: Easier to fine-tune and adapt to specific domains
    Control: Better understanding and control of model behavior
    Cost: Lower operational costs for training and inference
    Privacy: Can be run locally without sending data to external APIs
    Green Technology: Advocates efficient usage of resources with reduced carbon footprint
    Easier Academic Research Development: Provides an easy starter for academic research with cutting-edge LLMs with less logistical constraints




## Anything LLM
https://github.com/Mintplex-Labs/anything-llm



## Ollama

ollama.com

https://github.com/ollama/ollama

Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models. 


Run LLMs locally without internet with Ollama
https://medium.com/@pratikgtm/run-llms-locally-without-internet-with-ollama-1305ee83ceb7


## GPT4All

nomic.ai/gpt4all

https://github.com/nomic-ai/gpt4all

 GPT4All runs large language models (LLMs) privately on everyday desktops & laptops.

No API calls or GPUs required - you can just download the application and get started. 



## Llama.cpp

https://github.com/ggerganov/llama.cpp

Inference of Meta's LLaMA model (and others) in pure C/C++

The main goal of llama.cpp is to enable LLM inference with minimal setup and state-of-the-art performance on a wide variety of hardware - locally and in the cloud.

    Plain C/C++ implementation without any dependencies
    Apple silicon is a first-class citizen - optimized via ARM NEON, Accelerate and Metal frameworks
    AVX, AVX2, AVX512 and AMX support for x86 architectures
    1.5-bit, 2-bit, 3-bit, 4-bit, 5-bit, 6-bit, and 8-bit integer quantization for faster inference and reduced memory use
    Custom CUDA kernels for running LLMs on NVIDIA GPUs (support for AMD GPUs via HIP and Moore Threads MTT GPUs via MUSA)
    Vulkan and SYCL backend support
    CPU+GPU hybrid inference to partially accelerate models larger than the total VRAM capacity

Since its inception, the project has improved significantly thanks to many contributions. It is the main playground for developing new features for the ggml library.


## gpt4free

The official gpt4free repository | various collection of powerful language models 

https://g4f.ai

https://github.com/xtekky/gpt4free



## private-gpt

PrivateGPT is a production-ready AI project that allows you to ask questions about your documents using the power of Large Language Models (LLMs), even in scenarios without an Internet connection. 100% private, no data leaves your execution environment at any point.

https://github.com/zylon-ai/private-gpt

 privategpt.dev 

 ## Open WebUI

 Open WebUI is an extensible, feature-rich, and user-friendly self-hosted WebUI designed to operate entirely offline. It supports various LLM runners, including Ollama and OpenAI-compatible APIs. For more information, be sure to check out our Open WebUI Documentation.

 https://github.com/open-webui/open-webui

  openwebui.com 


## Lobe Chat

An open-source, modern-design ChatGPT/LLMs UI/Framework.
Supports speech-synthesis, multi-modal, and extensible (function call) plugin system.

https://github.com/lobehub/lobe-chat

 chat-preview.lobehub.com 

 ## Text generation web UI

A Gradio web UI for Large Language Models.

Its goal is to become the AUTOMATIC1111/stable-diffusion-webui of text generation.

https://github.com/oobabooga/text-generation-webui


## vllm

vLLM is a fast and easy-to-use library for LLM inference and serving.

vLLM is fast with:

    State-of-the-art serving throughput
    Efficient management of attention key and value memory with PagedAttention
    Continuous batching of incoming requests
    Fast model execution with CUDA/HIP graph
    Quantizations: GPTQ, AWQ, INT4, INT8, and FP8.
    Optimized CUDA kernels, including integration with FlashAttention and FlashInfer.
    Speculative decoding
    Chunked prefill

https://github.com/vllm-project/vllm


## AnythingLLM

AnythingLLM: The all-in-one AI app you were looking for.
Chat with your docs, use AI Agents, hyper-configurable, multi-user, & no frustrating set up required. 

https://github.com/Mintplex-Labs/anything-llm

anythingllm.com


## jan

Jan is an open source alternative to ChatGPT that runs 100% offline on your computer. Multiple engine support (llama.cpp, TensorRT-LLM) 

https://github.com/janhq/jan

jan.ai/

## localGPT

LocalGPT is an open-source initiative that allows you to converse with your documents without compromising your privacy. With everything running locally, you can be assured that no data ever leaves your computer. Dive into the world of secure, local document interactions with LocalGPT.

https://github.com/PromtEngineer/localGPT


## koboldcpp

KoboldCpp is an easy-to-use AI text-generation software for GGML and GGUF models, inspired by the original KoboldAI. It's a single self-contained distributable from Concedo, that builds off llama.cpp, and adds a versatile KoboldAI API endpoint, additional format support, Stable Diffusion image generation, speech-to-text, backward compatibility, as well as a fancy UI with persistent stories, editing tools, save formats, memory, world info, author's note, characters, scenarios and everything KoboldAI and KoboldAI Lite have to offer.


https://github.com/LostRuins/koboldcpp




# Text - Translation



# Text - RAG

## Sort

https://medium.com/@nydas/building-an-offline-rag-chatbot-with-custom-frontend-and-websockets-3a739878adf1

https://github.com/jonfairbanks/local-rag




## Datasets

https://www.reddit.com/r/LocalLLaMA/comments/1bjlzna/whats_the_fastest_route_to_success_to_performing/

https://huggingface.co/datasets/legacy-datasets/wikipedia

## WikiChat

Large language model (LLM) chatbots like ChatGPT and GPT-4 get things wrong a lot, especially if the information you are looking for is recent ("Tell me about the 2024 Super Bowl.") or about less popular topics ("What are some good movies to watch from [insert your favorite foreign director]?"). WikiChat uses Wikipedia and the following 7-stage pipeline to makes sure its responses are factual. Each numbered stage involves one or more LLM calls.

https://github.com/stanford-oval/WikiChat



##  Android-Document-QA

A simple Android app that allows the user to add a PDF/DOCX document and ask natural-language questions whose answers are generated by the means of an LLM


https://github.com/shubham0204/Android-Document-QA




# Code

## Why might this be useful for community networking and/or capacity building?

In underconnected communities without access to resources such as stackoverflow, offline ML coding tools could be use for software development and education. 


## Qwen2.5

Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters. 

https://huggingface.co/Qwen/Qwen2.5-72B-Instruct

https://github.com/QwenLM/Qwen2.5

https://arxiv.org/pdf/2409.12186

https://ollama.com/library/qwen2.5-coder

https://venturebeat.com/ai/alibaba-new-ai-can-code-in-92-languages-and-its-completely-free/

https://www.reddit.com/r/LocalLLaMA/comments/1h7nsg2/are_you_still_happy_with_qwen25_coder_32b/

## Claude 3.5 Sonnet

https://www.anthropic.com/news/3-5-models-and-computer-use


# Image Generation



## Fooocus

Fooocus presents a rethinking of image generator designs. The software is offline, open source, and free, while at the same time, similar to many online image generators like Midjourney, the manual tweaking is not needed, and users only need to focus on the prompts and images. Fooocus has also simplified the installation: between pressing "download" and generating the first image, the number of needed mouse clicks is strictly limited to less than 3. Minimal GPU memory requirement is 4GB (Nvidia).

https://github.com/lllyasviel/Fooocus


## Generative AI for Krita

https://github.com/Acly/krita-ai-diffusion

This is a plugin to use generative AI in image painting and editing workflows from within Krita. For a more visual introduction, see www.interstice.cloud

The main goals of this project are:

    Precision and Control. Creating entire images from text can be unpredictable. To get the result you envision, you can restrict generation to selections, refine existing content with a variable degree of strength, focus text on image regions, and guide generation with reference images, sketches, line art, depth maps, and more.
    Workflow Integration. Most image generation tools focus heavily on AI parameters. This project aims to be an unobtrusive tool that integrates and synergizes with image editing workflows in Krita. Draw, paint, edit and generate seamlessly without worrying about resolution and technical details.
    Local, Open, Free. We are committed to open source models. Customize presets, bring your own models, and run everything local on your hardware. Cloud generation is also available to get started quickly without heavy investment.



## SD.Next

https://github.com/vladmandic/automatic

SD.Next: Advanced Implementation of Stable Diffusion and other Diffusion-based generative image models 


## Stable Diffusion web UI


A web interface for Stable Diffusion, implemented using Gradio library.

https://github.com/AUTOMATIC1111/stable-diffusion-webui


## ComfyUI

The most powerful and modular diffusion model GUI and backend.

https://github.com/comfyanonymous/ComfyUI




# Audio


## Whisper

Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.

A Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.

https://github.com/openai/whisper

https://arxiv.org/pdf/2212.04356


#### How to install and use Whisper offline (no internet required)

Purpose: These instructions cover the steps not explicitly set out on the main Whisper page, e.g. for those who have never used python code/apps before and do not have the prerequisite software already installed.

https://github.com/openai/whisper/discussions/1463

https://github.com/Purfview/whisper-standalone-win




## local-talking-llm

After my latest post about how to build your own RAG and run it locally. Today, we're taking it a step further by not only implementing the conversational abilities of large language models but also adding listening and speaking capabilities. The idea is straightforward: we are going to create a voice assistant reminiscent of Jarvis or Friday from the iconic Iron Man movies, which can operate offline on your computer. Since this is an introductory tutorial, I will implement it in Python and keep it simple enough for beginners. Lastly, I will provide some guidance on how to scale the application. 

https://github.com/vndee/local-talking-llm




## Music

### FluxMusic

https://github.com/feizc/FluxMusic

Text-to-Music Generation with Rectified Flow Transformers 


### OpenMusic

OpenMusic: SOTA Text-to-music (TTM) Generation 

https://github.com/ivcylc/qa-mdt



# Video Generation


## Awesome Video Diffusion

A curated list of recent diffusion models for video generation, editing, restoration, understanding, nerf, etc.

https://github.com/showlab/Awesome-Video-Diffusion


## CogVideo
text and image to video generation

https://github.com/THUDM/CogVideo

Demo: https://huggingface.co/spaces/THUDM/CogVideoX-5B-Space


## LTX-Video

LTX-Video is the first DiT-based video generation model that can generate high-quality videos in real-time. It can generate 24 FPS videos at 768x512 resolution, faster than it takes to watch them. The model is trained on a large-scale dataset of diverse videos and can generate high-resolution videos with realistic and diverse content.

https://github.com/Lightricks/LTX-Video



# CAD Generation

## Why might this be useful for community networking and/or capacity building?

Users without technical expertise in 3D printing/additive manufacturing would be able to type in a prompt or use a reference image to generate a 3D model which could be printed/built locally. For example one could type the dimensions of a mount or bracket, or hardware case, to produce a CAD model for local production.



## Trellis

https://trellis3d.github.io/

https://github.com/Microsoft/TRELLIS

https://huggingface.co/spaces/JeffreyXiang/TRELLIS


TRELLIS is a large 3D asset generation model. It takes in text or image prompts and generates high-quality 3D assets in various formats, such as Radiance Fields, 3D Gaussians, and meshes. The cornerstone of TRELLIS is a unified Structured LATent (SLAT) representation that allows decoding to different output formats and Rectified Flow Transformers tailored for SLAT as the powerful backbones. We provide large-scale pre-trained models with up to 2 billion parameters on a large 3D asset dataset of 500K diverse objects. TRELLIS significantly surpasses existing methods, including recent ones at similar scales, and showcases flexible output format selection and local 3D editing capabilities which were not offered by previous models.


## Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts
https://sadilkhan.github.io/text2cad-project/

